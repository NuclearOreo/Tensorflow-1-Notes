{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Basic Approach (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using tensorflow to download the MNIST Dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Grabbing the MNIST Dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the type\n",
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the array of images\n",
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the number of training examples\n",
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the number of testing examples\n",
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the matplotlib to display the image correctly \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grabbing one image and reshaping it into a 28 by 28 array\n",
    "oneImage = mnist.train.images[100].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x137597908>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing the image\n",
    "plt.imshow(oneImage, cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholder\n",
    "x = tf.placeholder(tf.float32, shape=[None,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Graph Operations\n",
    "y = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholder for loss function\n",
    "y_true = tf.placeholder(tf.float32, [None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the loss\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Global Variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9163\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for _ in range(1000):\n",
    "        \n",
    "        batch_x, batch_y = mnist.train.next_batch(100)\n",
    "        \n",
    "        sess.run(train, feed_dict={x:batch_x, y_true:batch_y})\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_true,1))\n",
    "    \n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    print(sess.run(acc, feed_dict={x:mnist.test.images,y_true: mnist.test.labels}))\n",
    "    \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
